# TwitterData-Analysis-Uisng-Flume
This project Process Twitter data using Flume and stores it in Hadoop. The data is processed with Apache Flume on Local Machine and then stored in HDFS as Logs.

## Key Features
* Data Engineering: Implement a data pipeline to process twitter data.
* Tech Stack: Twitter API, Apache Flume, Apache Hadoop.
* Error Handling: Handle common errors and provide troubleshooting tips for a smooth workflow.

## Architecture

## Environment SetUp
### Hardware Used
#### Local Machine:

  Windows 11
  4 vCore, 4 GiB Memory, 32 GiB Storage
  
### Prerequisites
* Twitter API
* Apache Flume
* Apache Hadoop

## Project Implementation
1. Launch EC2 instance and install Apache Kafka, Apache Spark Streaming and Cassandra.
2. Create a JSP script to build web application and integrate kafka producer code in it.
3. Use Apache Kafka to produce the data to a topic.
4. Create a new spark streaming script to consume topic data and store it in CassandraDB.
## Execution
1. Launch an EC2 instance as well as Apache Kafka,SparkStreaming.
2. Start Apache Kafka producer to produce data to a topic.
3. Guve some clicks on web application to produce data in real-time.
4. Start spark streaming script to consume and store data in CassandraDB.
5. Use SQL to query data stored in CassandraDB.

## Error Handling and Troubleshooting
The following are common errors and troubleshooting tips for this project:

* Apache Flume Configuration Error:
* Apache Invalid credentials:
* Apache Hadoop Configuration Error:

## Conclusion
This project demonstrates the use of Twitter API, Apache Flume and Apache Hadoopto to retrieve and analyze twitter hastag as hdfs logs.
